# ğŸ“Š **Datasets Available vs. What You Need to Create**

## âœ… **What's Already Provided**

### **1. Sample Training Dataset (Ready to Use)**
- **Location**: `training_data/` directory
- **Size**: ~4,380 training samples (based on JSON file length)
- **Format**: Both YOLO and Florence2 formats included
- **Source images**: 12 unique mobile app interface screenshots
- **Content**: 
  - Live streaming app interfaces 
  - Video player controls
  - User profile screens
  - Login interfaces

### **2. Pre-processed Data Structure**
```
training_data/
â”œâ”€â”€ florence_format/           # For Florence2 caption training
â”‚   â”œâ”€â”€ florence_data.json     # 4,380 training entries
â”‚   â””â”€â”€ imgs/                  # 200+ augmented training images
â”œâ”€â”€ yolo_format/              # For YOLO detection training  
â”‚   â”œâ”€â”€ train/                # Training images + annotations
â”‚   â”œâ”€â”€ val/                  # Validation images + annotations
â”‚   â””â”€â”€ dataset.yaml          # YOLO configuration
â”œâ”€â”€ manual_correction.csv     # For data quality improvement
â””â”€â”€ *.json                   # Individual processing results
```

### **3. Sample Images in `imgs/` Directory**
- **50+ demo images** showing various UI types:
  - Windows applications (Excel, Word, Teams, OneNote)
  - Web interfaces (Google, DNS settings)
  - Mobile interfaces (iOS, Android)
  - OmniParser result visualizations

### **4. Data Augmentation Results**
- **200+ augmented images** already generated in `training_data/florence_format/imgs/`
- Various transformations applied (rotation, brightness, contrast, noise, scaling)
- Ready for immediate training use

## âŒ **What You Need to Create**

### **1. Domain-Specific Datasets (If Required)**
If you want to train for specific use cases beyond the provided mobile interface examples:

```bash
# Collect your own screenshots
mkdir raw_images
# Add your screenshots here

# Generate training data
python collect_training_data.py --input_dir ./raw_images --output_dir ./my_training_data
```

### **2. Manual Data Corrections (Optional)**
```bash
# Generate data with manual correction capability
python collect_training_data.py --manual_correction

# Edit the generated CSV file manually
# Apply corrections
python collect_training_data.py --apply_corrections
```

## ğŸš€ **Quick Start Options**

### **Option 1: Use Existing Data (Fastest)**
```bash
# Train immediately with provided data
python finetune_omniparser_lora.py --epochs 10

# Or use K-fold for better results
python finetune_omniparser_lora_kfold.py --k_folds 5
```

### **Option 2: Expand Existing Data**
```bash
# Increase data variety with augmentation
python data_augmentation.py --data_dir training_data/florence_format --multiplier 5

# Then train
python finetune_omniparser_lora_kfold.py
```

### **Option 3: Create Custom Dataset**
```bash
# Collect new data for your specific domain
python collect_training_data.py --input_dir ./your_screenshots --output_dir ./your_training_data

# Augment the data
python data_augmentation.py --data_dir ./your_training_data/florence_format --multiplier 3

# Train
python finetune_omniparser_lora.py
```

## ğŸ“‹ **Provided Dataset Details**

### **Image Types in Existing Dataset**
- **Mobile streaming app interfaces**: Live channels, video players, user profiles
- **Interactive elements**: Buttons, icons, text fields, navigation controls
- **Text content**: Both English and Spanish UI elements
- **Quality**: Professionally captured mobile interface screenshots

### **Annotation Quality**
- **Manual corrections applied**: CSV file shows human-verified labels
- **Source tracking**: Elements marked as OCR, YOLO, or combined detection
- **Coordinate precision**: Normalized bounding boxes (0-1 scale)
- **Content descriptions**: Semantic labels for each UI element

## ğŸ’¡ **Recommendations**

### **For Quick Testing**
âœ… **Use the existing dataset** - it's ready to go and covers common mobile UI patterns

### **For Production Use**
âœ… **Create your own dataset** using `collect_training_data.py` with your specific interface screenshots

### **For Best Results**
âœ… **Combine both approaches**:
1. Start with existing data for baseline training
2. Add your domain-specific screenshots
3. Apply manual corrections where needed
4. Use data augmentation to expand variety

## ğŸ¯ **Bottom Line**

**You DON'T need to create datasets from scratch** - there's already a substantial training dataset with 4,380 samples ready to use. However, **for domain-specific applications** (like your particular APK interfaces), you'll want to supplement this with your own screenshots using the provided data collection tools.

The existing dataset is perfect for:
- Learning how to use the training pipeline
- Getting baseline results quickly  
- Understanding the data format and quality standards
- Training a general-purpose mobile interface parser